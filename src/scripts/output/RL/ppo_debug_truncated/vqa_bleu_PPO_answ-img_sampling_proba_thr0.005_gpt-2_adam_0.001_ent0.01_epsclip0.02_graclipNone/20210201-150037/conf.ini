[main]
data_path = data/vqa-v2
features_path = data/vqa-v2/coco_trainval.lmdb
out_path = output/RL/ppo_debug_truncated
model = lstm
num_layers = 1
word_emb_size = 32
attention_dim = 64
hidden_size = 64
conv_kernel = 1
stride = 2
num_filters = 3
fusion = cat
agent = PPO
k_epochs = 20
update_every = 20
entropy_coeff = 0.01
eps_clip = 0.02
optimizer = adam
opt_schedule = None
div_factor = 25
lr = 0.001
grad_clip = None
policy_path = None
env = vqa
max_len = 10
gamma = 1.0
reward = bleu
reward_path = None
reward_vocab = None
mask_answers = 1
answer_sampl = img_sampling
curriculum = 0
debug = 0,69000
num_questions = 10
diff_reward = 0
condition_answer = none
min_data = 1
lm_path = gpt
truncate_mode = proba_thr
num_truncated = 10
p_th = 0.005
top_p = 1.0
s_min = 10
s_max = 200
temperature = 1.0
temp_step = 1
temp_factor = 1.0
temp_min = 1.0
temp_max = 10.0
inv_schedule_step = 0
schedule_start = 1
alpha_logits = 0.0
alpha_decay_rate = 0.0
epsilon_truncated = 0.0
epsilon_truncated_rate = 1
is_loss_correction = 1
init_text = None
custom_init = 0
add_answers = 0
num_episodes_train = 10
num_episodes_test = 10
train_seed = 0
test_seed = 1
resume_training = None
eval_no_trunc = 1
train_metrics = ['return', 'size_valid_actions', 'ppl_dialog_lm', 'ttr_question', 'valid_actions', 'valid_actions_episode', 'lm_valid_actions', 'dialog', 'eps_truncation', 'histogram_answers', 'ttr', 'sum_probs', 'true_word_rank', 'true_word_prob', 'action_probs_truncated', 'dialogimage']
test_metrics = ['return', 'dialog', 'bleu', 'ppl_dialog_lm', 'size_valid_actions', 'action_probs_truncated', 'ttr_question', 'sum_probs', 'ppl', 'lv_norm', 'ttr', 'selfbleu', 'dialogimage', 'valid_actions', 'language_score']
test_modes = ['test_images']
logger_level = INFO
log_interval = 10
pretrain = 0
device_id = 0
num_diversity = 1
reduced_answers = 0
params_reward = 10

