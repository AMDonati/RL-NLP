#!/bin/bash
python src/scripts/run.py -max_len 43 -data_path "data" -out_path "output/RL/20000_img_len_43_vqa" -model "lstm" -update_every 64 -agent "PPO" -K_epochs 10 -eps_clip 0.02 -lr 0.001 -word_emb_size 32 -hidden_size 64 -num_episodes_train 50000 -num_truncated 87 -debug "0,20000" -grad_clip 1 -lm_path "output/lm_model/model.pt" -reward "vqa" -reward_path "output/vqa_model_film/model.pt" -condition_answer "after_fusion" -num_episodes_test 200 -truncate_mode "proba_thr" -p_th 0.05 -train_seed 1 -num_questions 8 -reward_vocab "data/closure_vocab.json" -mask_answers 1
python src/scripts/run.py -max_len 43 -data_path "data" -out_path "output/RL/20000_img_len_43_vqa" -model "lstm" -update_every 64 -agent "PPO" -K_epochs 10 -eps_clip 0.02 -lr 0.001 -word_emb_size 32 -hidden_size 64 -num_episodes_train 50000 -num_truncated 20 -debug "0,20000" -grad_clip 1 -lm_path "output/lm_model/model.pt" -reward "vqa" -reward_path "output/vqa_model_film/model.pt" -condition_answer "after_fusion" -num_episodes_test 200 -truncate_mode "sample_va" -train_seed 1 -num_questions 8 -reward_vocab "data/closure_vocab.json" -mask_answers 1
python src/scripts/run.py -max_len 43 -data_path "data" -out_path "output/RL/20000_img_len_43_vqa" -model "lstm" -update_every 64 -agent "PPO" -K_epochs 10 -eps_clip 0.02 -lr 0.001 -word_emb_size 32 -hidden_size 64 -num_episodes_train 50000 -num_truncated 10 -debug "0,20000" -grad_clip 1 -lm_path "output/lm_model/model.pt" -reward "vqa" -reward_path "output/vqa_model_film/model.pt" -condition_answer "after_fusion" -num_episodes_test 200 -truncate_mode "top_k" -train_seed 1 -num_questions 8 -reward_vocab "data/closure_vocab.json" -mask_answers 1
python src/scripts/run.py -max_len 43 -data_path "data" -out_path "output/RL/20000_img_len_43_vqa" -model "lstm" -update_every 64 -agent "PPO" -K_epochs 10 -eps_clip 0.02 -lr 0.001 -word_emb_size 32 -hidden_size 64 -num_episodes_train 50000 -num_truncated 87 -debug "0,20000" -grad_clip 1 -lm_path "output/lm_model/model.pt" -reward "vqa" -reward_path "output/vqa_model_film/model.pt" -condition_answer "after_fusion" -num_episodes_test 200  -train_seed 1 -num_questions 8 -reward_vocab "data/closure_vocab.json" -mask_answers 1

python src/scripts/run.py -max_len 43 -data_path "data" -out_path "output/RL/20000_img_len_43_vqa" -model "lstm" -update_every 64 -agent "PPO" -K_epochs 10 -eps_clip 0.02 -lr 0.001 -word_emb_size 32 -hidden_size 64 -num_episodes_train 50000 -num_truncated 87 -debug "0,20000" -grad_clip 1 -lm_path "output/lm_model/model.pt" -reward "vqa" -reward_path "output/vqa_model_film/model.pt" -condition_answer "after_fusion" -num_episodes_test 200 -truncate_mode "proba_thr" -p_th 0.05 -train_seed 1 -num_questions 8 -reward_vocab "data/closure_vocab.json" -mask_answers 1 -policy_path "data/pretrained_model_answer.pt" -test_baselines
python src/scripts/run.py -max_len 43 -data_path "data" -out_path "output/RL/20000_img_len_43_vqa" -model "lstm" -update_every 64 -agent "PPO" -K_epochs 10 -eps_clip 0.02 -lr 0.001 -word_emb_size 32 -hidden_size 64 -num_episodes_train 50000 -num_truncated 20 -debug "0,20000" -grad_clip 1 -lm_path "output/lm_model/model.pt" -reward "vqa" -reward_path "output/vqa_model_film/model.pt" -condition_answer "after_fusion" -num_episodes_test 200 -truncate_mode "sample_va" -train_seed 1 -num_questions 8 -reward_vocab "data/closure_vocab.json" -mask_answers 1 -policy_path "data/pretrained_model_answer.pt" -test_baselines
python src/scripts/run.py -max_len 43 -data_path "data" -out_path "output/RL/20000_img_len_43_vqa" -model "lstm" -update_every 64 -agent "PPO" -K_epochs 10 -eps_clip 0.02 -lr 0.001 -word_emb_size 32 -hidden_size 64 -num_episodes_train 50000 -num_truncated 10 -debug "0,20000" -grad_clip 1 -lm_path "output/lm_model/model.pt" -reward "vqa" -reward_path "output/vqa_model_film/model.pt" -condition_answer "after_fusion" -num_episodes_test 200 -truncate_mode "top_k" -train_seed 1 -num_questions 8 -reward_vocab "data/closure_vocab.json" -mask_answers 1 -policy_path "data/pretrained_model_answer.pt" -test_baselines
python src/scripts/run.py -max_len 43 -data_path "data" -out_path "output/RL/20000_img_len_43_vqa" -model "lstm" -update_every 64 -agent "PPO" -K_epochs 10 -eps_clip 0.02 -lr 0.001 -word_emb_size 32 -hidden_size 64 -num_episodes_train 50000 -num_truncated 20 -debug "0,20000" -grad_clip 1 -lm_path "output/lm_model/model.pt" -reward "vqa" -reward_path "output/vqa_model_film/model.pt" -condition_answer "after_fusion" -num_episodes_test 200 -truncate_mode "top_k" -train_seed 1 -num_questions 8 -reward_vocab "data/closure_vocab.json" -mask_answers 1 -policy_path "data/pretrained_model_answer.pt" -test_baselines
python src/scripts/run.py -max_len 43 -data_path "data" -out_path "output/RL/20000_img_len_43_vqa" -model "lstm" -update_every 64 -agent "PPO" -K_epochs 10 -eps_clip 0.02 -lr 0.001 -word_emb_size 32 -hidden_size 64 -num_episodes_train 50000 -num_truncated 87 -debug "0,20000" -lm_path "output/lm_model/model.pt" -reward "vqa" -reward_path "output/vqa_model_film/model.pt" -condition_answer "after_fusion" -num_episodes_test 200  -train_seed 1 -num_questions 8 -reward_vocab "data/closure_vocab.json" -mask_answers 1 -policy_path "data/pretrained_model_answer.pt" -test_baselines
