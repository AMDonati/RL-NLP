#!/usr/bin/env bash
#python src/scripts/run.py -max_len 40 -data_path "data" -out_path "output/RL/20000_img_len_40_vqa_mask_1" -model "lstm" -update_every 64 -agent "PPO" -K_epochs 10 -eps_clip 0.02 -word_emb_size 32 -hidden_size 64 -num_episodes_train 50000 -debug "0,20000" -num_questions 8 -lm_path "output/model.pt" -entropy_coeff 0.02 -condition_answer "after_fusion" -reward_path "../CLOSURE/model.pt" -reward vqa -reward_vocab "../CLOSURE/data/vocab.json" -mask_answers 1  -train_seed 1 -test_baselines 1
#python src/scripts/run.py -max_len 40 -data_path "data" -out_path "output/RL/20000_img_len_40_vqa_mask_1" -model "lstm" -update_every 64 -agent "PPO" -K_epochs 10 -eps_clip 0.02 -word_emb_size 32 -hidden_size 64 -num_episodes_train 30000 -debug "0,20000" -num_questions 8 -lm_path "output/model.pt" -entropy_coeff 0.02 -condition_answer "after_fusion" -reward_path "../CLOSURE/model.pt" -reward vqa -reward_vocab "../CLOSURE/data/vocab.json" -mask_answers 1   -policy_path "output/policy_pre_training/SL_LSTM_L_1_emb_32_hid_64_pdrop_0_gc_None_bs_512_lr_0.001_fusion-cat/model.pt" -test_baselines 1

#python src/scripts/run.py -max_len 40 -data_path "data" -out_path "output/RL/20000_img_len_40_vqa_mask_2" -model "lstm" -update_every 64 -agent "PPO" -K_epochs 10 -eps_clip 0.02 -word_emb_size 32 -hidden_size 64 -num_episodes_train 30000 -debug "0,20000" -grad_clip 1 -num_questions 8 -lm_path "output/model.pt" -entropy_coeff 0.02 -condition_answer "after_fusion" -reward_path "../CLOSURE/model.pt" -reward vqa -reward_vocab "../CLOSURE/data/vocab.json" -mask_answers 1  -truncate_mode "top_k" -num_truncated 10 -test_baselines 1
#python src/scripts/run.py -max_len 40 -data_path "data" -out_path "output/RL/20000_img_len_40_vqa_mask_2" -model "lstm" -update_every 64 -agent "PPO" -K_epochs 10 -eps_clip 0.02 -word_emb_size 32 -hidden_size 64 -num_episodes_train 30000 -debug "0,20000" -grad_clip 1 -num_questions 8 -lm_path "output/model.pt" -entropy_coeff 0.02 -condition_answer "after_fusion" -reward_path "../CLOSURE/model.pt" -reward vqa -reward_vocab "../CLOSURE/data/vocab.json" -mask_answers 1 -truncate_mode "proba_thr" -p_th 0.05
#python src/scripts/run.py -max_len 40 -data_path "data" -out_path "output/RL/20000_img_len_40_vqa_mask_2" -model "lstm" -update_every 64 -agent "PPO" -K_epochs 10 -eps_clip 0.02 -word_emb_size 32 -hidden_size 64 -num_episodes_train 30000 -debug "0,20000" -grad_clip 1 -num_questions 8 -lm_path "output/model.pt" -entropy_coeff 0.02 -condition_answer "after_fusion" -reward_path "../CLOSURE/model.pt" -reward vqa -reward_vocab "../CLOSURE/data/vocab.json" -mask_answers 1 -truncate_mode "sample_va" -num_truncated 20

#python src/scripts/run.py -max_len 40 -data_path "data" -out_path "output/RL/20000_img_len_40_vqa_mask_2" -model "lstm" -update_every 64 -agent "PPO" -K_epochs 10 -eps_clip 0.02 -word_emb_size 32 -hidden_size 64 -num_episodes_train 30000 -debug "0,20000" -grad_clip 1 -num_questions 8 -lm_path "output/model.pt" -entropy_coeff 0.02 -condition_answer "after_fusion" -reward_path "../CLOSURE/model.pt" -reward vqa -reward_vocab "../CLOSURE/data/vocab.json" -mask_answers 1 -truncate_mode "proba_thr" -p_th 0.05  -policy_path "output/policy_pre_training_2/SL_LSTM_L_1_emb_32_hid_64_pdrop_0_gc_None_bs_512_lr_0.001_fusion-cat/model.pt"
#python src/scripts/run.py -max_len 40 -data_path "data" -out_path "output/RL/20000_img_len_40_vqa_mask_2" -model "lstm" -update_every 64 -agent "PPO" -K_epochs 10 -eps_clip 0.02 -word_emb_size 32 -hidden_size 64 -num_episodes_train 30000 -debug "0,20000" -grad_clip 1 -num_questions 8 -lm_path "output/model.pt" -entropy_coeff 0.02 -condition_answer "after_fusion" -reward_path "../CLOSURE/model.pt" -reward vqa -reward_vocab "../CLOSURE/data/vocab.json" -mask_answers 1  -truncate_mode "top_k" -num_truncated 10 -policy_path "output/policy_pre_training_2/SL_LSTM_L_1_emb_32_hid_64_pdrop_0_gc_None_bs_512_lr_0.001_fusion-cat/model.pt"
#python src/scripts/run.py -max_len 40 -data_path "data" -out_path "output/RL/20000_img_len_40_vqa_mask_2" -model "lstm" -update_every 64 -agent "PPO" -K_epochs 10 -eps_clip 0.02 -word_emb_size 32 -hidden_size 64 -num_episodes_train 30000 -debug "0,20000" -grad_clip 1 -num_questions 8 -lm_path "output/model.pt" -entropy_coeff 0.02 -condition_answer "after_fusion" -reward_path "../CLOSURE/model.pt" -reward vqa -reward_vocab "../CLOSURE/data/vocab.json" -mask_answers 1 -truncate_mode "sample_va" -num_truncated 20  -policy_path "output/policy_pre_training_2/SL_LSTM_L_1_emb_32_hid_64_pdrop_0_gc_None_bs_512_lr_0.001_fusion-cat/model.pt"


python src/scripts/run.py -max_len 40 -data_path "data" -out_path "output/RL/20000_img_len_40_vqa_mask_2" -model "lstm" -update_every 64 -agent "PPO" -K_epochs 10 -eps_clip 0.02 -word_emb_size 32 -hidden_size 64 -num_episodes_train 30000 -debug "0,20000" -grad_clip 1 -num_questions 8 -lm_path "output/model.pt" -entropy_coeff 0.02 -condition_answer "after_fusion" -reward_path "../CLOSURE/model.pt" -reward vqa -reward_vocab "../CLOSURE/data/vocab.json" -mask_answers 1 -policy_path "output/policy_pre_training_2/SL_LSTM_L_1_emb_32_hid_64_pdrop_0_gc_None_bs_512_lr_0.001_fusion-cat/model.pt"


python src/scripts/run.py -max_len 20 -data_path "data" -out_path "output/RL/20000_img_len_40_vqa_mask_3" -model "lstm" -update_every 64 -agent "PPO" -K_epochs 10 -eps_clip 0.02 -word_emb_size 32 -hidden_size 64 -num_episodes_train 30000 -debug "0,20000" -num_questions 8 -lm_path "output/model.pt" -entropy_coeff 0.02 -condition_answer "none" -reward levenshtein_ -policy_path "data/pretrained_policy/model.pt"
