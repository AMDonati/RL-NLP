#!/bin/bash
python src/scripts/run.py -max_len 10 -data_path "data" -out_path "output/RL/ppo_1img_len_10_diffreward" -model "lstm" -update_every 20 -agent "REINFORCE" -K_epochs 10 -eps_clip 0.02 -lr 0.005 -word_emb_size 8 -hidden_size 24 -num_episodes_train 5000  -debug "0,1" -num_questions 1 -entropy_coeff 0.01 -diff_reward 1 -gradclip 1
python src/scripts/run.py -max_len 10 -data_path "data" -out_path "output/RL/ppo_1img_len_10_diffreward" -model "lstm" -update_every 20 -agent "REINFORCE" -K_epochs 10 -eps_clip 0.02 -lr 0.005 -word_emb_size 8 -hidden_size 24 -num_episodes_train 5000 -lm_path "output/lm_model/model.pt" -debug "0,1" -num_questions 1 -entropy_coeff 0.01 -num_truncated 10 -diff_reward 1 -gradclip 1
python src/scripts/run.py -max_len 10 -data_path "data" -out_path "output/RL/ppo_1img_len_10_diffreward" -model "lstm" -update_every 20 -agent "REINFORCE" -K_epochs 10 -eps_clip 0.02 -lr 0.005 -word_emb_size 8 -hidden_size 24 -num_episodes_train 5000 -lm_path "output/lm_model/model.pt" -debug "0,1" -num_questions 1 -entropy_coeff 0.01 -num_truncated 20 -diff_reward 1 -gradclip 1
python src/scripts/run.py -max_len 10 -data_path "data" -out_path "output/RL/ppo_1img_len_10_diffreward" -model "lstm" -update_every 20 -agent "REINFORCE" -K_epochs 10 -eps_clip 0.02 -lr 0.005 -word_emb_size 8 -hidden_size 24 -num_episodes_train 5000 -lm_path "output/lm_model/model.pt" -debug "0,1" -num_questions 1 -entropy_coeff 0.01 -num_truncated 30 -diff_reward 1 -gradclip 1
python src/scripts/run.py -max_len 10 -data_path "data" -out_path "output/RL/ppo_1img_len_10_diffreward" -model "lstm" -update_every 20 -agent "REINFORCE" -K_epochs 10 -eps_clip 0.02 -lr 0.005 -word_emb_size 8 -hidden_size 24 -num_episodes_train 5000 -lm_path "output/lm_model/model.pt" -debug "0,1" -num_questions 1 -entropy_coeff 0.01 -num_truncated 10 -diff_reward 1 -gradclip 1
python src/scripts/run.py -max_len 10 -data_path "data" -out_path "output/RL/ppo_1img_len_10_diffreward" -model "lstm" -update_every 20 -agent "REINFORCE" -K_epochs 10 -eps_clip 0.02 -lr 0.005 -word_emb_size 8 -hidden_size 24 -num_episodes_train 5000 -lm_path "output/lm_model/model.pt" -debug "0,1" -num_questions 1 -entropy_coeff 0.01 -num_truncated 20 -diff_reward 1 -gradclip 1
python src/scripts/run.py -max_len 10 -data_path "data" -out_path "output/RL/ppo_1img_len_10_diffreward" -model "lstm" -update_every 20 -agent "REINFORCE" -K_epochs 10 -eps_clip 0.02 -lr 0.005 -word_emb_size 8 -hidden_size 24 -num_episodes_train 5000 -lm_path "output/lm_model/model.pt" -debug "0,1" -num_questions 1 -entropy_coeff 0.01 -num_truncated 30 -diff_reward 1 -gradclip 1


