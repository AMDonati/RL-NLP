#!/usr/bin/env bash
#python src/scripts/run.py -env "vqa" -max_len 10 -data_path "data/vqa-v2" -out_path "output/RL/VQA_debug_pretrained_baseline/gradclip" -model "lstm" -update_every 128 -agent "PPO" -K_epochs 20 -eps_clip 0.05 -lr 0.001 -word_emb_size 512 -hidden_size 1024 -num_episodes_train 5000 -debug "0,2000" -lm_path "gpt" -reward "bleu_sf2" -num_episodes_test 100 -mask_answers 1 -fusion "average" -condition_answer "after_fusion" -policy_path "output/vqa_policy_512_1024_answer_smallvocab/model.pt" -device_id 2 -min_data 1
python src/scripts/run.py -env "vqa" -max_len 10 -data_path "data/vqa-v2" -out_path "output/RL/VQA_debug_pretrained_baseline/gradclip" -model "lstm" -update_every 128 -agent "PPO" -K_epochs 20 -eps_clip 0.05 -lr 0.001 -word_emb_size 512 -hidden_size 1024 -num_episodes_train 5000 -debug "0,2000" -lm_path "gpt" -reward "bleu_sf2" -num_episodes_test 100 -mask_answers 1 -fusion "average" -condition_answer "after_fusion" -policy_path "output/vqa_policy_512_1024_answer_smallvocab/model.pt" -device_id 2 -min_data 1 -grad_clip 0.1
python src/scripts/run.py -env "vqa" -max_len 10 -data_path "data/vqa-v2" -out_path "output/RL/VQA_debug_pretrained_baseline/gradclip" -model "lstm" -update_every 128 -agent "PPO" -K_epochs 20 -eps_clip 0.05 -lr 0.001 -word_emb_size 512 -hidden_size 1024 -num_episodes_train 5000 -debug "0,2000" -lm_path "gpt" -reward "bleu_sf2" -num_episodes_test 100 -mask_answers 1 -fusion "average" -condition_answer "after_fusion" -policy_path "output/vqa_policy_512_1024_answer_smallvocab/model.pt" -device_id 2 -min_data 1 -grad_clip 0.5
python src/scripts/run.py -env "vqa" -max_len 10 -data_path "data/vqa-v2" -out_path "output/RL/VQA_debug_pretrained_baseline/gradclip" -model "lstm" -update_every 128 -agent "PPO" -K_epochs 20 -eps_clip 0.05 -lr 0.001 -word_emb_size 512 -hidden_size 1024 -num_episodes_train 5000 -debug "0,2000" -lm_path "gpt" -reward "bleu_sf2" -num_episodes_test 100 -mask_answers 1 -fusion "average" -condition_answer "after_fusion" -policy_path "output/vqa_policy_512_1024_answer_smallvocab/model.pt" -device_id 2 -min_data 1 -grad_clip 1
python src/scripts/run.py -env "vqa" -max_len 10 -data_path "data/vqa-v2" -out_path "output/RL/VQA_debug_pretrained_baseline/gradclip" -model "lstm" -update_every 128 -agent "PPO" -K_epochs 20 -eps_clip 0.05 -lr 0.001 -word_emb_size 512 -hidden_size 1024 -num_episodes_train 5000 -debug "0,2000" -lm_path "gpt" -reward "bleu_sf2" -num_episodes_test 100 -mask_answers 1 -fusion "average" -condition_answer "after_fusion" -policy_path "output/vqa_policy_512_1024_answer_smallvocab/model.pt" -device_id 2 -min_data 1 -grad_clip 5
python src/scripts/run.py -env "vqa" -max_len 10 -data_path "data/vqa-v2" -out_path "output/RL/VQA_debug_pretrained_baseline/gradclip" -model "lstm" -update_every 128 -agent "PPO" -K_epochs 20 -eps_clip 0.05 -lr 0.001 -word_emb_size 512 -hidden_size 1024 -num_episodes_train 5000 -debug "0,2000" -lm_path "gpt" -reward "bleu_sf2" -num_episodes_test 100 -mask_answers 1 -fusion "average" -condition_answer "after_fusion" -policy_path "output/vqa_policy_512_1024_answer_smallvocab/model.pt" -device_id 2 -min_data 1 -grad_clip 10
python src/scripts/run.py -env "vqa" -max_len 10 -data_path "data/vqa-v2" -out_path "output/RL/VQA_debug_pretrained_baseline/gradclip" -model "lstm" -update_every 128 -agent "PPO" -K_epochs 20 -eps_clip 0.05 -lr 0.001 -word_emb_size 512 -hidden_size 1024 -num_episodes_train 5000 -debug "0,2000" -lm_path "gpt" -reward "bleu_sf2" -num_episodes_test 100 -mask_answers 1 -fusion "average" -condition_answer "after_fusion" -policy_path "output/vqa_policy_512_1024_answer_smallvocab/model.pt" -device_id 2 -min_data 1 -grad_clip 100


