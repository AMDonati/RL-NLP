#!/usr/bin/env bash
echo "---- lr = 0.0000005 -----------------------"
python src/scripts/run.py -env "vqa" -max_len 10 -data_path "data/vqa-v2" -out_path "output/RL/VQA_debug_pretrained_baseline/sgd_warmup" -model "lstm" -update_every 128 -agent "PPO" -optimizer "adam" -lr 0.001 -word_emb_size 512 -hidden_size 1024 -num_episodes_train 10000 -debug "0,2000" -lm_path "gpt" -reward "bleu_sf2" -num_episodes_test 100 -mask_answers 1 -fusion "average" -condition_answer "after_fusion" -policy_path "output/vqa_policy_512_1024_answer_smallvocab/model.pt" -device_id 2 -min_data 1 -lr 0.000001
python src/scripts/run.py -env "vqa" -max_len 10 -data_path "data/vqa-v2" -out_path "output/RL/VQA_debug_pretrained_baseline/sgd_warmup" -model "lstm" -update_every 128 -agent "PPO" -optimizer "rmsprop" -lr 0.001 -word_emb_size 512 -hidden_size 1024 -num_episodes_train 10000 -debug "0,2000" -lm_path "gpt" -reward "bleu_sf2" -num_episodes_test 100 -mask_answers 1 -fusion "average" -condition_answer "after_fusion" -policy_path "output/vqa_policy_512_1024_answer_smallvocab/model.pt" -device_id 2 -min_data 1 -lr 0.0000005
python src/scripts/run.py -env "vqa" -max_len 10 -data_path "data/vqa-v2" -out_path "output/RL/VQA_debug_pretrained_baseline/sgd_warmup" -model "lstm" -update_every 128 -agent "PPO" -optimizer "sgd" -lr 0.001 -word_emb_size 512 -hidden_size 1024 -num_episodes_train 10000 -debug "0,2000" -lm_path "gpt" -reward "bleu_sf2" -num_episodes_test 100 -mask_answers 1 -fusion "average" -condition_answer "after_fusion" -policy_path "output/vqa_policy_512_1024_answer_smallvocab/model.pt" -device_id 2 -min_data 1 -lr 0.0000005
python src/scripts/run.py -env "vqa" -max_len 10 -data_path "data/vqa-v2" -out_path "output/RL/VQA_debug_pretrained_baseline/sgd_warmup" -model "lstm" -update_every 128 -agent "PPO" -optimizer "sgd" -lr 0.001 -opt_schedule "cyclic" -word_emb_size 512 -hidden_size 1024 -num_episodes_train 10000 -debug "0,2000" -lm_path "gpt" -reward "bleu_sf2" -num_episodes_test 100 -mask_answers 1 -fusion "average" -condition_answer "after_fusion" -policy_path "output/vqa_policy_512_1024_answer_smallvocab/model.pt" -device_id 2 -min_data 1 -lr 0.0000005
python src/scripts/run.py -env "vqa" -max_len 10 -data_path "data/vqa-v2" -out_path "output/RL/VQA_debug_pretrained_baseline/sgd_warmup" -model "lstm" -update_every 128 -agent "PPO" -optimizer "sgd" -lr 0.001 -opt_schedule "cyclic_multi" -word_emb_size 512 -hidden_size 1024 -num_episodes_train 10000 -debug "0,2000" -lm_path "gpt" -reward "bleu_sf2" -num_episodes_test 100 -mask_answers 1 -fusion "average" -condition_answer "after_fusion" -policy_path "output/vqa_policy_512_1024_answer_smallvocab/model.pt" -device_id 2 -min_data 1 -lr 0.0000005
python src/scripts/run.py -env "vqa" -max_len 10 -data_path "data/vqa-v2" -out_path "output/RL/VQA_debug_pretrained_baseline/sgd_warmup" -model "lstm" -update_every 128 -agent "PPO" -optimizer "sgd" -lr 0.001 -opt_schedule "WR" -word_emb_size 512 -hidden_size 1024 -num_episodes_train 10000 -debug "0,2000" -lm_path "gpt" -reward "bleu_sf2" -num_episodes_test 100 -mask_answers 1 -fusion "average" -condition_answer "after_fusion" -policy_path "output/vqa_policy_512_1024_answer_smallvocab/model.pt" -device_id 2 -min_data 1 -lr 0.0000005