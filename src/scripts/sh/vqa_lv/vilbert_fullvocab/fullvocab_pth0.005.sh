#!/usr/bin/env bash
#python src/scripts/run.py -env "vqa" -max_len 10 -data_path "data/vqa-v2" -out_path "output/RL/temp" -model "lstm" -update_every 128 -agent "PPO" -K_epochs 20 -eps_clip 0.01 -lr 0.00005 -word_emb_size 512 -hidden_size 1024 -num_episodes_train 10 -debug "0,20000" -lm_path "output/vqa_lm_model/model.pt" -reward "bleu_sf2" -num_episodes_test 1 -mask_answers 1 -truncate_mode "proba_thr" -grad_clip 5 -fusion "average" -condition_answer "after_fusion" -device_id 0 -temperature 2 -temp_step 1000 -temp_factor 0.75 -temp_min 0.7 -p_th 0.005 -s_min 1 -s_max 200 -entropy_coeff 0.01 -reward "vilbert" -reward_vocab "output/vilbert_vqav2/bert_base_6layer_6conect.json" -reward_path "output/vilbert_vqav2/model.bin"
python src/scripts/run.py -env "vqa" -max_len 10 -data_path "data/vqa-v2" -out_path "output/RL/VILBERT_VQA_fullvocab/temperature_pth_512_1024/50_000ep" -model "lstm" -update_every 128 -agent "PPO" -K_epochs 20 -eps_clip 0.01 -lr 0.00005 -word_emb_size 512 -hidden_size 1024 -num_episodes_train 50000 -debug "0,20000" -lm_path "output/vqa_lm_model/model.pt" -num_episodes_test 500 -mask_answers 1 -truncate_mode "proba_thr" -grad_clip 5 -fusion "average" -condition_answer "after_fusion" -device_id 0 -temperature 2 -temp_step 1000 -temp_factor 0.75 -temp_min 0.7 -p_th 0.005 -s_min 1 -s_max 200 -entropy_coeff 0.01 -reward "vilbert" -reward_vocab "output/vilbert_vqav2/bert_base_6layer_6conect.json" -reward_path "output/vilbert_vqav2/model.bin"
python src/scripts/run.py -env "vqa" -max_len 10 -data_path "data/vqa-v2" -out_path "output/RL/VILBERT_VQA_fullvocab/temperature_pth_512_1024/hparams/s_min10" -model "lstm" -update_every 128 -agent "PPO" -K_epochs 20 -eps_clip 0.01 -lr 0.00005 -word_emb_size 512 -hidden_size 1024 -num_episodes_train 20000 -debug "0,20000" -lm_path "output/vqa_lm_model/model.pt" -num_episodes_test 500 -mask_answers 1 -truncate_mode "proba_thr" -grad_clip 5 -fusion "average" -condition_answer "after_fusion" -device_id 0 -temperature 2 -temp_step 1000 -temp_factor 0.75 -temp_min 0.7 -p_th 0.005 -s_min 10 -s_max 200 -entropy_coeff 0.01 -reward "vilbert" -reward_vocab "output/vilbert_vqav2/bert_base_6layer_6conect.json" -reward_path "output/vilbert_vqav2/model.bin"
python src/scripts/run.py -env "vqa" -max_len 10 -data_path "data/vqa-v2" -out_path "output/RL/VILBERT_VQA_fullvocab/temperature_pth_512_1024/50_000ep" -model "lstm" -update_every 128 -agent "PPO" -K_epochs 20 -eps_clip 0.01 -lr 0.00005 -word_emb_size 512 -hidden_size 1024 -num_episodes_train 50000 -debug "0,20000" -lm_path "output/vqa_lm_model/model.pt" -num_episodes_test 500 -mask_answers 1 -truncate_mode "proba_thr" -grad_clip 5 -fusion "average" -condition_answer "after_fusion" -device_id 1 -temperature 2 -temp_step 1000 -temp_factor 0.75 -temp_min 0.7 -p_th 0.005 -s_min 1 -s_max 200 -entropy_coeff 0.02 -reward "vilbert" -reward_vocab "output/vilbert_vqav2/bert_base_6layer_6conect.json" -reward_path "output/vilbert_vqav2/model.bin"
python src/scripts/run.py -env "vqa" -max_len 10 -data_path "data/vqa-v2" -out_path "output/RL/VILBERT_VQA_fullvocab/temperature_pth_512_1024/50_000ep" -model "lstm" -update_every 128 -agent "PPO" -K_epochs 20 -eps_clip 0.01 -lr 0.00005 -word_emb_size 512 -hidden_size 1024 -num_episodes_train 50000 -debug "0,20000" -lm_path "output/vqa_lm_model/model.pt" -num_episodes_test 500 -mask_answers 1 -truncate_mode "proba_thr" -grad_clip 5 -fusion "average" -condition_answer "after_fusion" -device_id 2 -temperature 2 -temp_step 1000 -temp_factor 0.75 -temp_min 0.7 -p_th 0.005 -s_min 1 -s_max 200 -entropy_coeff 0.025 -reward "vilbert" -reward_vocab "output/vilbert_vqav2/bert_base_6layer_6conect.json" -reward_path "output/vilbert_vqav2/model.bin"

python src/scripts/run.py -env "vqa" -max_len 10 -data_path "data/vqa-v2" -out_path "output/RL/VILBERT_VQA_fullvocab/temperature_pth_512_1024/50_000ep" -model "lstm" -update_every 128 -agent "REINFORCE" -K_epochs 20 -eps_clip 0.01 -lr 0.00001 -word_emb_size 512 -hidden_size 1024 -num_episodes_train 50000 -debug "0,20000" -lm_path "output/vqa_lm_model/model.pt" -num_episodes_test 500 -mask_answers 1 -grad_clip 5 -fusion "average" -condition_answer "after_fusion" -device_id 3  -entropy_coeff 0.01 -reward "vilbert" -reward_vocab "output/vilbert_vqav2/bert_base_6layer_6conect.json" -reward_path "output/vilbert_vqav2/model.bin" -policy_path "output/vqa_policy_512_1024_answer/model.pt"


python src/scripts/run.py -env "vqa" -max_len 10 -data_path "data/vqa-v2" -out_path "output/RL/VILBERT_VQA_fullvocab/temperature_pth_512_1024/50_000ep/s_min10" -model "lstm" -update_every 128 -agent "PPO" -K_epochs 20 -eps_clip 0.01 -lr 0.00005 -word_emb_size 512 -hidden_size 1024 -num_episodes_train 50000 -debug "0,20000" -lm_path "output/vqa_lm_model/model.pt" -num_episodes_test 1000 -mask_answers 1 -truncate_mode "proba_thr" -grad_clip 5 -fusion "average" -condition_answer "after_fusion" -device_id 0 -temperature 2 -temp_step 5000 -temp_factor 0.75 -temp_min 0.7 -p_th 0.005 -s_min 10 -s_max 200 -entropy_coeff 0.01 -reward "vilbert" -reward_vocab "output/vilbert_vqav2/bert_base_6layer_6conect.json" -reward_path "output/vilbert_vqav2/model.bin"
python src/scripts/run.py -env "vqa" -max_len 10 -data_path "data/vqa-v2" -out_path "output/RL/VILBERT_VQA_fullvocab/temperature_pth_512_1024/50_000ep/s_min10" -model "lstm" -update_every 128 -agent "PPO" -K_epochs 20 -eps_clip 0.01 -lr 0.00005 -word_emb_size 512 -hidden_size 1024 -num_episodes_train 50000 -debug "0,20000" -lm_path "output/vqa_lm_model/model.pt" -num_episodes_test 1000 -mask_answers 1 -truncate_mode "proba_thr" -grad_clip 5 -fusion "average" -condition_answer "after_fusion" -device_id 1 -temperature 2 -temp_step 2500 -temp_factor 0.75 -temp_min 0.7 -p_th 0.005 -s_min 10 -s_max 200 -entropy_coeff 0.01 -reward "vilbert" -reward_vocab "output/vilbert_vqav2/bert_base_6layer_6conect.json" -reward_path "output/vilbert_vqav2/model.bin"
python src/scripts/run.py -env "vqa" -max_len 10 -data_path "data/vqa-v2" -out_path "output/RL/VILBERT_VQA_fullvocab/temperature_pth_512_1024/50_000ep/s_min10" -model "lstm" -update_every 128 -agent "PPO" -K_epochs 20 -eps_clip 0.01 -lr 0.00005 -word_emb_size 512 -hidden_size 1024 -num_episodes_train 50000 -debug "0,20000" -lm_path "output/vqa_lm_model/model.pt" -num_episodes_test 1000 -mask_answers 1 -truncate_mode "proba_thr" -grad_clip 5 -fusion "average" -condition_answer "after_fusion" -device_id 2 -temperature 2 -temp_step 1000 -temp_factor 0.75 -temp_min 0.7 -p_th 0.005 -s_min 10 -s_max 200 -entropy_coeff 0.01 -reward "vilbert" -reward_vocab "output/vilbert_vqav2/bert_base_6layer_6conect.json" -reward_path "output/vilbert_vqav2/model.bin"
python src/scripts/run.py -env "vqa" -max_len 10 -data_path "data/vqa-v2" -out_path "output/RL/VILBERT_VQA_fullvocab/temperature_pth_512_1024/50_000ep/s_min10" -model "lstm" -update_every 128 -agent "PPO" -K_epochs 20 -eps_clip 0.01 -lr 0.00005 -word_emb_size 512 -hidden_size 1024 -num_episodes_train 50000 -debug "0,20000" -lm_path "output/vqa_lm_model/model.pt" -num_episodes_test 1000 -mask_answers 1 -truncate_mode "proba_thr" -grad_clip 5 -fusion "average" -condition_answer "after_fusion" -device_id 3 -temperature 2 -temp_step 1000 -temp_factor 0.75 -temp_min 0.7 -p_th 0.004 -s_min 10 -s_max 200 -entropy_coeff 0.01 -reward "vilbert" -reward_vocab "output/vilbert_vqav2/bert_base_6layer_6conect.json" -reward_path "output/vilbert_vqav2/model.bin"

python src/scripts/run.py -env "vqa" -max_len 10 -data_path "data/vqa-v2" -out_path "output/RL/VILBERT_VQA_fullvocab/temperature_pth_512_1024/50000_ep/SL_baseline" -model "lstm" -update_every 128 -agent "REINFORCE" -K_epochs 20 -eps_clip 0.01 -lr 0.00001 -word_emb_size 512 -hidden_size 1024 -num_episodes_train 0 -debug "0,20000" -lm_path "output/vqa_lm_model/model.pt" -reward "vilbert" -reward_vocab "output/vilbert_vqav2/bert_base_6layer_6conect.json" -reward_path "output/vilbert_vqav2/model.bin" -num_episodes_test 500 -mask_answers 1 -fusion "average" -condition_answer "after_fusion" -device_id 2 -policy_path "output/vqa_policy_512_1024_answer/model.pt" -test_metrics "return" "dialog" "bleu" "ppl_dialog_lm" "ttr_question" "sum_probs" "ppl" "lv_norm" "ttr" "selfbleu" "dialogimage" "language_score"