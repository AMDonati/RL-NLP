#!/usr/bin/env bash
python src/scripts/run.py -env "vqa" -max_len 10 -data_path "data/vqa-v2" -out_path "output/RL/VQA_debug_pretrained_baseline/small_lr_reinforce" -model "lstm" -update_every 128 -agent "REINFORCE" -K_epochs 20 -eps_clip 0.02 -lr 0.00005 -word_emb_size 512 -hidden_size 1024 -num_episodes_train 10000 -debug "0,2000" -lm_path "gpt" -reward "bleu_sf2" -num_episodes_test 100 -mask_answers 1 -fusion "average" -condition_answer "after_fusion" -policy_path "output/vqa_policy_512_1024_answer_smallvocab/model.pt" -device_id 1 -min_data 1
python src/scripts/run.py -env "vqa" -max_len 10 -data_path "data/vqa-v2" -out_path "output/RL/VQA_debug_pretrained_baseline/small_lr_reinforce" -model "lstm" -update_every 128 -agent "REINFORCE" -K_epochs 20 -eps_clip 0.02 -lr 0.0001 -word_emb_size 512 -hidden_size 1024 -num_episodes_train 10000 -debug "0,2000" -lm_path "gpt" -reward "bleu_sf2" -num_episodes_test 100 -mask_answers 1 -fusion "average" -condition_answer "after_fusion" -policy_path "output/vqa_policy_512_1024_answer_smallvocab/model.pt" -device_id 1 -min_data 1
python src/scripts/run.py -env "vqa" -max_len 10 -data_path "data/vqa-v2" -out_path "output/RL/VQA_debug_pretrained_baseline/small_lr_reinforce" -model "lstm" -update_every 128 -agent "REINFORCE" -K_epochs 20 -eps_clip 0.02 -lr 0.00005 -word_emb_size 512 -hidden_size 1024 -num_episodes_train 10000 -debug "0,2000" -lm_path "gpt" -reward "bleu_sf2" -num_episodes_test 100 -mask_answers 1 -fusion "average" -condition_answer "after_fusion" -policy_path "output/vqa_policy_512_1024_answer_smallvocab/model.pt" -device_id 1 -min_data 1
python src/scripts/run.py -env "vqa" -max_len 10 -data_path "data/vqa-v2" -out_path "output/RL/VQA_debug_pretrained_baseline/small_lr_reinforce" -model "lstm" -update_every 128 -agent "REINFORCE" -K_epochs 20 -eps_clip 0.02 -lr 0.0001 -word_emb_size 512 -hidden_size 1024 -num_episodes_train 10000 -debug "0,2000" -lm_path "gpt" -reward "bleu_sf2" -num_episodes_test 100 -mask_answers 1 -fusion "average" -condition_answer "after_fusion" -policy_path "output/vqa_policy_512_1024_answer_smallvocab/model.pt" -device_id 1 -min_data 1
python src/scripts/run.py -env "vqa" -max_len 10 -data_path "data/vqa-v2" -out_path "output/RL/VQA_debug_pretrained_baseline/small_lr_reinforce" -model "lstm" -update_every 128 -agent "REINFORCE" -K_epochs 20 -eps_clip 0.02 -lr 0.00005 -word_emb_size 512 -hidden_size 1024 -num_episodes_train 10000 -debug "0,2000" -lm_path "gpt" -reward "bleu_sf2" -num_episodes_test 100 -mask_answers 1 -fusion "average" -condition_answer "after_fusion" -policy_path "output/vqa_policy_512_1024_answer_smallvocab/model.pt" -device_id 1 -min_data 1
python src/scripts/run.py -env "vqa" -max_len 10 -data_path "data/vqa-v2" -out_path "output/RL/VQA_debug_pretrained_baseline/small_lr_reinforce" -model "lstm" -update_every 128 -agent "REINFORCE" -K_epochs 20 -eps_clip 0.02 -lr 0.0001 -word_emb_size 512 -hidden_size 1024 -num_episodes_train 10000 -debug "0,2000" -lm_path "gpt" -reward "bleu_sf2" -num_episodes_test 100 -mask_answers 1 -fusion "average" -condition_answer "after_fusion" -policy_path "output/vqa_policy_512_1024_answer_smallvocab/model.pt" -device_id 1 -min_data 1
echo "----------train seed-----------"
python src/scripts/run.py -env "vqa" -max_len 10 -data_path "data/vqa-v2" -out_path "output/RL/VQA_debug_pretrained_baseline/small_lr_reinforce/train_seed" -model "lstm" -update_every 128 -agent "REINFORCE" -K_epochs 20 -eps_clip 0.02 -lr 0.00005 -word_emb_size 512 -hidden_size 1024 -num_episodes_train 10000 -debug "0,2000" -lm_path "gpt" -reward "bleu_sf2" -num_episodes_test 100 -mask_answers 1 -fusion "average" -condition_answer "after_fusion" -policy_path "output/vqa_policy_512_1024_answer_smallvocab/model.pt" -device_id 1 -min_data 1 -train_seed 1
python src/scripts/run.py -env "vqa" -max_len 10 -data_path "data/vqa-v2" -out_path "output/RL/VQA_debug_pretrained_baseline/small_lr_reinforce/train_seed" -model "lstm" -update_every 128 -agent "REINFORCE" -K_epochs 20 -eps_clip 0.02 -lr 0.0001 -word_emb_size 512 -hidden_size 1024 -num_episodes_train 10000 -debug "0,2000" -lm_path "gpt" -reward "bleu_sf2" -num_episodes_test 100 -mask_answers 1 -fusion "average" -condition_answer "after_fusion" -policy_path "output/vqa_policy_512_1024_answer_smallvocab/model.pt" -device_id 1 -min_data 1 -train_seed 1
python src/scripts/run.py -env "vqa" -max_len 10 -data_path "data/vqa-v2" -out_path "output/RL/VQA_debug_pretrained_baseline/small_lr_reinforce/train_seed" -model "lstm" -update_every 128 -agent "REINFORCE" -K_epochs 20 -eps_clip 0.02 -lr 0.00005 -word_emb_size 512 -hidden_size 1024 -num_episodes_train 10000 -debug "0,2000" -lm_path "gpt" -reward "bleu_sf2" -num_episodes_test 100 -mask_answers 1 -fusion "average" -condition_answer "after_fusion" -policy_path "output/vqa_policy_512_1024_answer_smallvocab/model.pt" -device_id 1 -min_data 1 -train_seed 1
python src/scripts/run.py -env "vqa" -max_len 10 -data_path "data/vqa-v2" -out_path "output/RL/VQA_debug_pretrained_baseline/small_lr_reinforce/train_seed" -model "lstm" -update_every 128 -agent "REINFORCE" -K_epochs 20 -eps_clip 0.02 -lr 0.0001 -word_emb_size 512 -hidden_size 1024 -num_episodes_train 10000 -debug "0,2000" -lm_path "gpt" -reward "bleu_sf2" -num_episodes_test 100 -mask_answers 1 -fusion "average" -condition_answer "after_fusion" -policy_path "output/vqa_policy_512_1024_answer_smallvocab/model.pt" -device_id 1 -min_data 1 -train_seed 1
python src/scripts/run.py -env "vqa" -max_len 10 -data_path "data/vqa-v2" -out_path "output/RL/VQA_debug_pretrained_baseline/small_lr_reinforce/train_seed" -model "lstm" -update_every 128 -agent "REINFORCE" -K_epochs 20 -eps_clip 0.02 -lr 0.00005 -word_emb_size 512 -hidden_size 1024 -num_episodes_train 10000 -debug "0,2000" -lm_path "gpt" -reward "bleu_sf2" -num_episodes_test 100 -mask_answers 1 -fusion "average" -condition_answer "after_fusion" -policy_path "output/vqa_policy_512_1024_answer_smallvocab/model.pt" -device_id 1 -min_data 1 -train_seed 1
python src/scripts/run.py -env "vqa" -max_len 10 -data_path "data/vqa-v2" -out_path "output/RL/VQA_debug_pretrained_baseline/small_lr_reinforce/train_seed" -model "lstm" -update_every 128 -agent "REINFORCE" -K_epochs 20 -eps_clip 0.02 -lr 0.0001 -word_emb_size 512 -hidden_size 1024 -num_episodes_train 10000 -debug "0,2000" -lm_path "gpt" -reward "bleu_sf2" -num_episodes_test 100 -mask_answers 1 -fusion "average" -condition_answer "after_fusion" -policy_path "output/vqa_policy_512_1024_answer_smallvocab/model.pt" -device_id 1 -min_data 1 -train_seed 1