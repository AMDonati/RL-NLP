#!/usr/bin/env bash
# LV REWARD:
echo "-------------------------- Scratch ---------------------------------------------------------------------------------------------------"
python src/scripts/run.py -max_len 5 -data_path "data" -out_path "output/RL/ppo_debug_truncated" -model "lstm" -update_every 10 -agent "PPO" -K_epochs 20 -eps_clip 0.02 -lr 0.001 -word_emb_size 8 -hidden_size 24 -num_episodes_train 10 -lm_path "output/lm_model/model.pt" -debug "0,1" -grad_clip 1 -num_episodes_test 10 -eval_no_trunc 1
echo "------------------------- pretrain ----------------------------------------------------------------------------------------------------"
python src/scripts/run.py -max_len 5 -data_path "data" -out_path "output/RL/ppo_debug_truncated" -model "lstm" -update_every 10 -agent "PPO" -K_epochs 20 -eps_clip 0.02 -lr 0.001 -word_emb_size 32 -hidden_size 64 -num_episodes_train 10 -lm_path "output/lm_model/model.pt" -debug "0,1" -num_episodes_test 10 -eval_no_trunc 1 -policy_path "output/SL_LSTM_32_64/model.pt"
echo "------------------------- top k ----------------------------------------------------------------------------------------------------"
python src/scripts/run.py -max_len 5 -data_path "data" -out_path "output/RL/ppo_debug_truncated" -model "lstm" -update_every 10 -agent "PPO" -K_epochs 20 -eps_clip 0.02 -lr 0.001 -word_emb_size 8 -hidden_size 24 -num_episodes_train 10 -lm_path "output/lm_model/model.pt" -num_truncated 20 -debug "0,1" -grad_clip 1 -truncate_mode "top_k" -num_episodes_test 10 -eval_no_trunc 1
echo "------------------------- sample_va ----------------------------------------------------------------------------------------------------"
python src/scripts/run.py -max_len 5 -data_path "data" -out_path "output/RL/ppo_debug_truncated" -model "lstm" -update_every 10 -agent "PPO" -K_epochs 20 -eps_clip 0.02 -lr 0.001 -word_emb_size 8 -hidden_size 24 -num_episodes_train 10 -lm_path "output/lm_model/model.pt" -num_truncated 20 -debug "0,1" -grad_clip 1 -truncate_mode "sample_va" -num_episodes_test 10 -eval_no_trunc 1
echo "------------------------- proba threshold ----------------------------------------------------------------------------------------------------"
python src/scripts/run.py -max_len 5 -data_path "data" -out_path "output/RL/ppo_debug_truncated" -model "lstm" -update_every 10 -agent "PPO" -K_epochs 20 -eps_clip 0.02 -lr 0.001 -word_emb_size 8 -hidden_size 24 -num_episodes_train 10 -lm_path "output/lm_model/model.pt" -num_truncated 20 -debug "0,1" -grad_clip 1 -truncate_mode "proba_thr" -num_episodes_test 10 -eval_no_trunc 1
echo "-------------------------  top p ---------------------------------------------------------------------------------------------------------------"
python src/scripts/run.py -max_len 5 -data_path "data" -out_path "output/RL/ppo_debug_truncated" -model "lstm" -update_every 10 -agent "PPO" -K_epochs 20 -eps_clip 0.02 -lr 0.001 -word_emb_size 8 -hidden_size 24 -num_episodes_train 10 -lm_path "output/lm_model/model.pt" -num_truncated 20 -debug "0,1" -grad_clip 1 -truncate_mode "top_p" -top_p 0.8 -num_episodes_test 10 -eval_no_trunc 1
echo "------------------------- sample_va + pretrain ----------------------------------------------------------------------------------------------------"
python src/scripts/run.py -max_len 5 -data_path "data" -out_path "output/RL/ppo_debug_truncated" -model "lstm" -update_every 10 -agent "PPO" -K_epochs 20 -eps_clip 0.02 -lr 0.001 -word_emb_size 32 -hidden_size 64 -num_episodes_train 10 -lm_path "output/lm_model/model.pt" -num_truncated 20 -debug "0,1" -grad_clip 1 -num_questions 8 -truncate_mode "sample_va" -num_episodes_test 10 -eval_no_trunc 1 -train_seed 1 -policy_path "output/SL_LSTM_32_64/model.pt"
echo "------------------------- sample_va + epsilon truncation ----------------------------------------------------------------------------------------------------"
python src/scripts/run.py -max_len 5 -data_path "data" -out_path "output/RL/ppo_debug_truncated" -model "lstm" -update_every 10 -agent "PPO" -K_epochs 20 -eps_clip 0.02 -lr 0.001 -word_emb_size 32 -hidden_size 64 -num_episodes_train 10 -lm_path "output/lm_model/model.pt" -num_truncated 20 -debug "0,1" -grad_clip 1 -num_questions 8 -truncate_mode "sample_va" -num_episodes_test 10 -epsilon_truncated 0.2 -eval_no_trunc 1 -train_seed 1
echo "------------------------- sample_va + GPT2 ----------------------------------------------------------------------------------------------------"
python src/scripts/run.py -max_len 5 -data_path "data" -out_path "output/RL/ppo_debug_truncated" -model "lstm" -update_every 10 -agent "PPO" -K_epochs 20 -eps_clip 0.02 -lr 0.001 -word_emb_size 32 -hidden_size 64 -num_episodes_train 10 -num_truncated 20 -debug "0,1" -grad_clip 1 -num_questions 8 -truncate_mode "sample_va" -num_episodes_test 10 -epsilon_truncated 0.2 -eval_no_trunc 1 -train_seed 1